{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** SHUYUE JIA\n",
    "\n",
    "**EID:** 56846018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS5489 - Tutorial 4\n",
    "## Face Detection in Images\n",
    "\n",
    "In this tutorial you will train a classifier to detect whether there is a face in a small image patch.  This type of face detector is used in your phone and camera whenever you take a picture!\n",
    "\n",
    "First we need to initialize Python.  Run the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import IPython.core.display         \n",
    "# setup output image format (Chrome works best)\n",
    "IPython.core.display.set_matplotlib_formats(\"svg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from numpy import *\n",
    "from sklearn import *\n",
    "import os\n",
    "import zipfile\n",
    "import fnmatch\n",
    "random.seed(100)\n",
    "from scipy import ndimage\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "import skimage.color\n",
    "import skimage.exposure\n",
    "import skimage.io\n",
    "import skimage.util\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading Data and Pre-processing\n",
    "Next we need to load the images.  Download `faces.zip`, and put it in the same direcotry as this ipynb file.  **Do not unzip the file.** Then run the following cell to load the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnsupportedOperation",
     "evalue": "seek",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnsupportedOperation\u001B[0m                      Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-2-0ff6ed443348>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     41\u001B[0m             \u001B[0mmyfile\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mzfile\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     42\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 43\u001B[0;31m             \u001B[0mimg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmatplotlib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmyfile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     44\u001B[0m             \u001B[0;31m# img = skimage.io.imread(myfile)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     45\u001B[0m             \u001B[0;31m# convert to grayscale\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/matplotlib/image.py\u001B[0m in \u001B[0;36mimread\u001B[0;34m(fname, format)\u001B[0m\n\u001B[1;32m   1494\u001B[0m                     \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mio\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mBytesIO\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresponse\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1495\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mimread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresponse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mformat\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mext\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1496\u001B[0;31m     \u001B[0;32mwith\u001B[0m \u001B[0mimg_open\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfname\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mimage\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1497\u001B[0m         return (_pil_png_to_float_array(image)\n\u001B[1;32m   1498\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mPIL\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPngImagePlugin\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPngImageFile\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/PIL/ImageFile.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, fp, filename)\u001B[0m\n\u001B[1;32m    119\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    120\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 121\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_open\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    122\u001B[0m             except (\n\u001B[1;32m    123\u001B[0m                 \u001B[0mIndexError\u001B[0m\u001B[0;34m,\u001B[0m  \u001B[0;31m# end of data\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/PIL/PngImagePlugin.py\u001B[0m in \u001B[0;36m_open\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    689\u001B[0m             \u001B[0;31m# get next chunk\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    690\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 691\u001B[0;31m             \u001B[0mcid\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpos\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlength\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpng\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    692\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    693\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/PIL/PngImagePlugin.py\u001B[0m in \u001B[0;36mread\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    159\u001B[0m             \u001B[0ms\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m8\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    160\u001B[0m             \u001B[0mcid\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0ms\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m4\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 161\u001B[0;31m             \u001B[0mpos\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtell\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    162\u001B[0m             \u001B[0mlength\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mi32\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ms\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    163\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mUnsupportedOperation\u001B[0m: seek"
     ]
    }
   ],
   "source": [
    "imgdata = {'train':[], 'test':[]}\n",
    "classes = {'train':[], 'test':[]}\n",
    "\n",
    "# the dataset is too big, so subsample the training and test sets...\n",
    "# reduce training set by a factor of 4\n",
    "train_subsample = 4  \n",
    "train_counter = [0, 0]\n",
    "# maximum number of samples in each class for test set\n",
    "test_maxsample = 472\n",
    "test_counter = [0, 0]\n",
    "\n",
    "# load the zip file\n",
    "filename = 'faces.zip'\n",
    "zfile = zipfile.ZipFile(filename, 'r')\n",
    "\n",
    "for name in zfile.namelist():\n",
    "    # check file name matches\n",
    "    if fnmatch.fnmatch(name, \"faces/*/*/*.png\"):\n",
    "        \n",
    "        # filename is : faces/train/face/fname.png\n",
    "        (fdir1, fname)  = os.path.split(name)     # get file name\n",
    "        (fdir2, fclass) = os.path.split(fdir1) # get class (face, nonface)\n",
    "        (fdir3, fset)   = os.path.split(fdir2) # get training/test set\n",
    "        \n",
    "        # class 1 = face; class 0 = non-face\n",
    "        myclass = int(fclass == \"face\")  \n",
    "\n",
    "        loadme = False\n",
    "        if fset == 'train':\n",
    "            if (train_counter[myclass] % train_subsample) == 0:\n",
    "                loadme = True\n",
    "            train_counter[myclass] += 1\n",
    "            \n",
    "        elif fset == 'test':\n",
    "            if test_counter[myclass] < test_maxsample:\n",
    "                loadme = True\n",
    "            test_counter[myclass] += 1\n",
    "            \n",
    "        if (loadme):\n",
    "            # open file in memory, and parse as an image\n",
    "            myfile = zfile.open(name)\n",
    "            \n",
    "            img = matplotlib.image.imread(myfile)\n",
    "            # img = skimage.io.imread(myfile)\n",
    "            # convert to grayscale\n",
    "            img = skimage.color.rgb2gray(img)\n",
    "            myfile.close()\n",
    "            \n",
    "            # append data\n",
    "            imgdata[fset].append(img)\n",
    "            classes[fset].append(myclass)\n",
    "\n",
    "        \n",
    "zfile.close()\n",
    "imgsize = img.shape\n",
    "\n",
    "print(len(imgdata['train']))\n",
    "print(len(imgdata['test']))\n",
    "trainclass2start = sum(classes['train'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image is a 19x19 array of pixel values.  Run the below code to show an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img.shape)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(imgdata['train'][0], cmap='gray', interpolation='nearest')\n",
    "plt.title(\"face sample\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(imgdata['train'][trainclass2start], cmap='gray', interpolation='nearest')\n",
    "plt.title(\"non-face sample\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the below code to show more images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to make an image montage\n",
    "def image_montage(X, imsize=None, maxw=10):\n",
    "    \"\"\"X can be a list of images, or a matrix of vectorized images.\n",
    "      Specify imsize when X is a matrix.\"\"\"\n",
    "    tmp = []\n",
    "    numimgs = len(X)\n",
    "    \n",
    "    # create a list of images (reshape if necessary)\n",
    "    for i in range(0,numimgs):\n",
    "        if imsize != None:\n",
    "            tmp.append(X[i].reshape(imsize))\n",
    "        else:\n",
    "            tmp.append(X[i])\n",
    "    \n",
    "    # add blanks\n",
    "    if (numimgs > maxw) and (mod(numimgs, maxw) > 0):\n",
    "        leftover = maxw - mod(numimgs, maxw)\n",
    "        meanimg = 0.5*(X[0].max()+X[0].min())\n",
    "        for i in range(0,leftover):\n",
    "            tmp.append(ones(tmp[0].shape)*meanimg)\n",
    "    \n",
    "    # make the montage\n",
    "    tmp2 = []\n",
    "    for i in range(0,len(tmp),maxw):\n",
    "        tmp2.append( hstack(tmp[i:i+maxw]) )\n",
    "    montimg = vstack(tmp2) \n",
    "    return montimg\n",
    "\n",
    "# show a few images\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.imshow(image_montage(imgdata['train'][::20]), cmap='gray', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image is a 2d array, but the classifier algorithms work on 1d vectors. Run the following code to convert all the images into 1d vectors by flattening.  The result should be a matrix where each row is a flattened image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = empty((len(imgdata['train']), prod(imgsize)))\n",
    "for i,img in enumerate(imgdata['train']):\n",
    "    trainX[i,:] = ravel(img)\n",
    "trainY = asarray(classes['train'])  # convert list to numpy array\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "\n",
    "testX = empty((len(imgdata['test']), prod(imgsize)))\n",
    "for i,img in enumerate(imgdata['test']):\n",
    "    testX[i,:] = ravel(img)\n",
    "testY = asarray(classes['test'])  # convert list to numpy array\n",
    "print(testX.shape)\n",
    "print(testY.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Detection using  pixel values\n",
    "\n",
    "Train an AdaBoost and GradientBoosting classifiers to classify an image patch as face or non-face.  Also train a kernel SVM classifier using either RBF or polynomial kernel, and a Random Forest Classifier.  Evaluate all your classifiers on the test set.\n",
    "\n",
    "First we will normalize the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler(feature_range=(-1,1))    # make scaling object\n",
    "trainXn = scaler.fit_transform(trainX)   # use training data to fit scaling parameters\n",
    "testXn  = scaler.transform(testX)        # apply scaling to test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost Model\n",
    "# setup the list of parameters to try\n",
    "paramgrid = {'learning_rate': logspace(-6, 0, 3)} \n",
    "# print(paramgrid)\n",
    "\n",
    "# setup the cross-validation object \n",
    "adaclf = ensemble.AdaBoostClassifier(random_state=4487)\n",
    "adacv = model_selection.GridSearchCV(adaclf, paramgrid, cv=5, n_jobs=8) \n",
    "\n",
    "adacv.fit(trainX, trainY)\n",
    "# print(\"best params:\", adacv.best_params_)\n",
    "\n",
    "# predict from the model \n",
    "train_pre = adacv.predict(trainX)\n",
    "train_acc = metrics.accuracy_score(trainY, train_pre) \n",
    "print(\"(AdaBoost Model)\\n training accuracy =\", train_acc)\n",
    "\n",
    "# predict from the model \n",
    "test_pre = adacv.predict(testX)\n",
    "test_acc = metrics.accuracy_score(testY, test_pre) \n",
    "print(\"(AdaBoost Model)\\n testing accuracy =\", test_acc)\n",
    "\n",
    "# predY is the prediction from the classifier\n",
    "predY = test_pre\n",
    "Pind = where(predY == 1) # indicies for face predictions\n",
    "Nind = where(predY == 0) # indicies for non-face predictions\n",
    "TP = count_nonzero(testY[Pind] == predY[Pind])\n",
    "FP = count_nonzero(testY[Pind] != predY[Pind])\n",
    "TN = count_nonzero(testY[Nind] == predY[Nind])\n",
    "FN = count_nonzero(testY[Nind] != predY[Nind])\n",
    "\n",
    "TPR = TP / (TP + FN)\n",
    "FPR = FP / (FP + TN)\n",
    "\n",
    "print(\"TP =\", TP)\n",
    "print(\"FP =\", FP)\n",
    "print(\"TN =\", TN)\n",
    "print(\"FN =\", FN)\n",
    "print(\"TPR=\", TPR)\n",
    "print(\"FPR =\", FPR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GradientBoosting Model\n",
    "# use the XGBoost package, compatible with sklearn \n",
    "import xgboost as xgb\n",
    "\n",
    "# use \"multi:softprob\" for multi-class classification \n",
    "xclf = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=4487)\n",
    "\n",
    "# setup the list of parameters to try\n",
    "\n",
    "paramgrid = {'learning_rate': logspace(-6, 0, 3)} \n",
    "print(paramgrid)\n",
    "\n",
    "# setup the cross-validation object \n",
    "xgbcv = model_selection.GridSearchCV(xclf, paramgrid, cv=5, n_jobs=8)\n",
    "\n",
    "# run cross-validation (train for each split) \n",
    "xgbcv.fit(trainX, trainY)\n",
    "# print(\"best params:\", xgbcv.best_params_)\n",
    "\n",
    "# predict from the model \n",
    "train_pre = xgbcv.predict(trainX)\n",
    "train_acc = metrics.accuracy_score(trainY, train_pre) \n",
    "print(\"(GradientBoosting Model)\\n training accuracy =\", train_acc)\n",
    "\n",
    "# predict from the model \n",
    "test_pre = xgbcv.predict(testX)\n",
    "test_acc = metrics.accuracy_score(testY, test_pre) \n",
    "print(\"(GradientBoosting Model)\\n testing accuracy =\", test_acc)\n",
    "\n",
    "# predY is the prediction from the classifier\n",
    "predY = test_pre\n",
    "Pind = where(predY == 1) # indicies for face predictions\n",
    "Nind = where(predY == 0) # indicies for non-face predictions\n",
    "TP = count_nonzero(testY[Pind] == predY[Pind])\n",
    "FP = count_nonzero(testY[Pind] != predY[Pind])\n",
    "TN = count_nonzero(testY[Nind] == predY[Nind])\n",
    "FN = count_nonzero(testY[Nind] != predY[Nind])\n",
    "\n",
    "TPR = TP / (TP + FN)\n",
    "FPR = FP / (FP + TN)\n",
    "\n",
    "print(\"TP =\", TP)\n",
    "print(\"FP =\", FP)\n",
    "print(\"TN =\", TN)\n",
    "print(\"FN =\", FN)\n",
    "print(\"TPR=\", TPR)\n",
    "print(\"FPR =\", FPR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GradientBoosting Model\n",
    "# use the XGBoost package, compatible with sklearn \n",
    "import xgboost as xgb\n",
    "\n",
    "# setup dictionary of distributions for each parameter\n",
    "paramsampler = {    \n",
    "    \"colsample_bytree\": stats.uniform(0.7, 0.3),  # default=1\n",
    "#     \"gamma\":            stats.uniform(0, 0.5),    # default=0\n",
    "#     \"max_depth\":        stats.randint(2, 6),      # default=6\n",
    "#     \"subsample\":        stats.uniform(0.6, 0.4),  # default=1\n",
    "#     \"learning_rate\":    stats.uniform(.001, 1),    # default=1 (could also use loguniform)\n",
    "#     \"n_estimators\":     stats.randint(10, 1000),\n",
    "}\n",
    "\n",
    "xgbclf = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=4487)\n",
    "\n",
    "# cross-validation via random search\n",
    "xgbrcv = model_selection.RandomizedSearchCV(xgbclf, \n",
    "                                            param_distributions=paramsampler, \n",
    "                                            random_state=4487, \n",
    "                                            n_iter=100, \n",
    "                                            cv=5, \n",
    "                                            verbose=1, \n",
    "                                            n_jobs=8)\n",
    "\n",
    "\n",
    "# run cross-validation (train for each split) \n",
    "xgbrcv.fit(trainX, trainY)\n",
    "print(\"best params:\", xgbrcv.best_params_)\n",
    "\n",
    "# predict from the model \n",
    "train_pre = xgbrcv.predict(trainX)\n",
    "train_acc = metrics.accuracy_score(trainY, train_pre) \n",
    "print(\"(GradientBoosting Model with more search parameters)\\n training accuracy =\", train_acc)\n",
    "\n",
    "# predict from the model \n",
    "test_pre = xgbrcv.predict(testX)\n",
    "test_acc = metrics.accuracy_score(testY, test_pre) \n",
    "print(\"(GradientBoosting Model with more search parameters)\\n testing accuracy =\", test_acc)\n",
    "\n",
    "# predY is the prediction from the classifier\n",
    "predY = test_pre\n",
    "Pind = where(predY == 1) # indicies for face predictions\n",
    "Nind = where(predY == 0) # indicies for non-face predictions\n",
    "TP = count_nonzero(testY[Pind] == predY[Pind])\n",
    "FP = count_nonzero(testY[Pind] != predY[Pind])\n",
    "TN = count_nonzero(testY[Nind] == predY[Nind])\n",
    "FN = count_nonzero(testY[Nind] != predY[Nind])\n",
    "\n",
    "TPR = TP / (TP + FN)\n",
    "FPR = FP / (FP + TN)\n",
    "\n",
    "print(\"TP =\", TP)\n",
    "print(\"FP =\", FP)\n",
    "print(\"TN =\", TN)\n",
    "print(\"FN =\", FN)\n",
    "print(\"TPR=\", TPR)\n",
    "print(\"FPR =\", FPR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Model with RBF kernel\n",
    "# setup the list of parameters to try \n",
    "paramgrid = {'C': logspace(-2, 3, 3), \n",
    "             'gamma': logspace(-4, 3, 3)}\n",
    "print(paramgrid)\n",
    "\n",
    "# setup the cross-validation object \n",
    "# pass the SVM object w/ rbf kernel, parameter grid, and number of CV folds \n",
    "svmrbf = svm.SVC(kernel='rbf')\n",
    "svmrbfcv = model_selection.GridSearchCV(svmrbf, \n",
    "                                     paramgrid, \n",
    "                                     cv=5, \n",
    "                                     n_jobs=8, \n",
    "                                     verbose=True)\n",
    "\n",
    "# run cross-validation (train for each split) \n",
    "svmrbfcv.fit(trainX, trainY);\n",
    "print(\"best params:\", svmcv.best_params_)\n",
    "\n",
    "# predict from the model \n",
    "train_pre = svmrbfcv.predict(trainX)\n",
    "train_acc = metrics.accuracy_score(trainY, train_pre) \n",
    "print(\"(SVM Model with RBF kernel with more search parameters)\\n training accuracy =\", train_acc)\n",
    "\n",
    "# predict from the model \n",
    "test_pre = svmrbfcv.predict(testX)\n",
    "test_acc = metrics.accuracy_score(testY, test_pre) \n",
    "print(\"(SVM Model with RBF kernel with more search parameters)\\n testing accuracy =\", test_acc)\n",
    "\n",
    "# predY is the prediction from the classifier\n",
    "predY = test_pre\n",
    "Pind = where(predY == 1) # indicies for face predictions\n",
    "Nind = where(predY == 0) # indicies for non-face predictions\n",
    "TP = count_nonzero(testY[Pind] == predY[Pind])\n",
    "FP = count_nonzero(testY[Pind] != predY[Pind])\n",
    "TN = count_nonzero(testY[Nind] == predY[Nind])\n",
    "FN = count_nonzero(testY[Nind] != predY[Nind])\n",
    "\n",
    "TPR = TP / (TP + FN)\n",
    "FPR = FP / (FP + TN)\n",
    "\n",
    "print(\"TP =\", TP)\n",
    "print(\"FP =\", FP)\n",
    "print(\"TN =\", TN)\n",
    "print(\"FN =\", FN)\n",
    "print(\"TPR=\", TPR)\n",
    "print(\"FPR =\", FPR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Model with polynomial kernel\n",
    "# setup the list of parameters to try \n",
    "paramgrid = {'C': logspace(-2, 3, 3), \n",
    "             'gamma': logspace(-4, 3, 3)}\n",
    "print(paramgrid)\n",
    "\n",
    "# setup the cross-validation object # pass the SVM object w/ rbf kernel, parameter grid, and number of CV folds \n",
    "svmpol = svm.SVC(kernel='poly')\n",
    "svmpolcv = model_selection.GridSearchCV(svmpol, \n",
    "                                     paramgrid, \n",
    "                                     cv=5, \n",
    "                                     n_jobs=8, \n",
    "                                     verbose=True)\n",
    "\n",
    "# run cross-validation (train for each split) \n",
    "svmpolcv.fit(trainX, trainY);\n",
    "print(\"best params:\", svmcv.best_params_)\n",
    "\n",
    "# predict from the model \n",
    "train_pre = svmpolcv.predict(trainX)\n",
    "train_acc = metrics.accuracy_score(trainY, train_pre) \n",
    "print(\"(SVM Model with polynomial kernel with more search parameters)\\n training accuracy =\", train_acc)\n",
    "\n",
    "# predict from the model \n",
    "test_pre = svmpolcv.predict(testX)\n",
    "test_acc = metrics.accuracy_score(testY, test_pre) \n",
    "print(\"(SVM Model with polynomial kernel with more search parameters)\\n testing accuracy =\", test_acc)\n",
    "\n",
    "# predY is the prediction from the classifier\n",
    "predY = test_pre\n",
    "Pind = where(predY == 1) # indicies for face predictions\n",
    "Nind = where(predY == 0) # indicies for non-face predictions\n",
    "TP = count_nonzero(testY[Pind] == predY[Pind])\n",
    "FP = count_nonzero(testY[Pind] != predY[Pind])\n",
    "TN = count_nonzero(testY[Nind] == predY[Nind])\n",
    "FN = count_nonzero(testY[Nind] != predY[Nind])\n",
    "\n",
    "TPR = TP / (TP + FN)\n",
    "FPR = FP / (FP + TN)\n",
    "\n",
    "print(\"TP =\", TP)\n",
    "print(\"FP =\", FP)\n",
    "print(\"TN =\", TN)\n",
    "print(\"FN =\", FN)\n",
    "print(\"TPR=\", TPR)\n",
    "print(\"FPR =\", FPR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Model\n",
    "from sklearn import ensemble\n",
    "\n",
    "# setup the list of parameters to try\n",
    "paramsampler = {#'max_features': stats.uniform(0,1.0),\n",
    "                 'max_depth':         stats.randint(1, 5),\n",
    "                 'min_samples_split': stats.uniform(0, 0.5), \n",
    "                 'min_samples_leaf':  stats.uniform(0, 0.5)}\n",
    "\n",
    "rf = ensemble.RandomForestClassifier(n_estimators=100, random_state=4487, n_jobs=8)\n",
    "\n",
    "# setup the cross-validation object\n",
    "rfrcv = model_selection.RandomizedSearchCV(\n",
    "    rf,\n",
    "    param_distributions=paramsampler, \n",
    "    random_state=4487, \n",
    "    n_iter=100, \n",
    "    cv=5, \n",
    "    verbose=1, \n",
    "    n_jobs=8)\n",
    "\n",
    "# run cross-validation (train for each split)\n",
    "rfrcv.fit(trainX, trainY);\n",
    "print(\"best params:\", rfrcv.best_params_)\n",
    "\n",
    "# predict from the model \n",
    "train_pre = rfrcv.predict(trainX)\n",
    "train_acc = metrics.accuracy_score(trainY, train_pre) \n",
    "print(\"(Random Forest Model with more search parameters)\\n training accuracy =\", train_acc)\n",
    "\n",
    "# predict from the model \n",
    "test_pre = rfrcv.predict(testX)\n",
    "test_acc = metrics.accuracy_score(testY, test_pre) \n",
    "print(\"(Random Forest Model with more search parameters)\\n testing accuracy =\", test_acc)\n",
    "\n",
    "# predY is the prediction from the classifier\n",
    "predY = test_pre\n",
    "Pind = where(predY == 1) # indicies for face predictions\n",
    "Nind = where(predY == 0) # indicies for non-face predictions\n",
    "TP = count_nonzero(testY[Pind] == predY[Pind])\n",
    "FP = count_nonzero(testY[Pind] != predY[Pind])\n",
    "TN = count_nonzero(testY[Nind] == predY[Nind])\n",
    "FN = count_nonzero(testY[Nind] != predY[Nind])\n",
    "\n",
    "TPR = TP / (TP + FN)\n",
    "FPR = FP / (FP + TN)\n",
    "\n",
    "print(\"TP =\", TP)\n",
    "print(\"FP =\", FP)\n",
    "print(\"TN =\", TN)\n",
    "print(\"FN =\", FN)\n",
    "print(\"TPR=\", TPR)\n",
    "print(\"FPR =\", FPR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Which classifier was best?_\n",
    "- SVM Model with RBF kernel according to the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error analysis\n",
    "The accuracy only tells part of the classifier's performance. We can also look at the different types of errors that the classifier makes:\n",
    "- _True Positive (TP)_: classifier correctly said face\n",
    "- _True Negative (TN)_: classifier correctly said non-face\n",
    "- _False Positive (FP)_: classifier said face, but not a face\n",
    "- _False Negative (FN)_: classifier said non-face, but was a face\n",
    "\n",
    "This is summarized in the following table:\n",
    "\n",
    "<table>\n",
    "<tr><th colspan=2 rowspan=2><th colspan=2 style=\"text-align: center\">Actual</th></tr>\n",
    "<tr>  <th>Face</th><th>Non-face</th></tr>\n",
    "<tr><th rowspan=2>Prediction</th><th>Face</th><td>True Positive (TP)</td><td>False Positive (FP)</td></tr>\n",
    "<tr>  <th>Non-face</th><td>False Negative (FN)</td><td>True Negative (TN)</td></tr>\n",
    "</table>\n",
    "\n",
    "We can then look at the _true positive rate_ and the _false positive rate_.\n",
    "- _true positive rate (TPR)_: proportion of true faces that were correctly detected\n",
    "- _false positive rate (FPR)_: proportion of non-faces that were mis-classified as faces.\n",
    "\n",
    "Use the below code to calculate the TPR and FPR of your classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_How does the classifier make errors?_\n",
    "- As for the False Positive, the class should be Negative, but the model predicts positive. Besides, for the False Negative, the class should be positive, but the model predicts negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the AdaBoost classifier, we can interpret what it is doing by looking at which features it uses most in the weak learners.  Use the below code to visualize the pixel features used.\n",
    "\n",
    "Note: if you used GridSearchCV to train the classifier, then you need to use the `best_estimator_` field to access the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adacv is the trained adaboost classifier\n",
    "fi = adacv.best_estimator_.feature_importances_.reshape(imgsize)\n",
    "plt.imshow(fi, interpolation='nearest')\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can also look at the important features for xgboost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgbcv is the trained xgboost classifier\n",
    "fi = xgbcv.best_estimator_.feature_importances_.reshape(imgsize)\n",
    "plt.imshow(fi, interpolation='nearest')\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly for Random Forests, we can look at the important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# rfrcv is the trained random forest classifier\n",
    "fi = rfrcv.best_estimator_.feature_importances_.reshape(imgsize)\n",
    "plt.imshow(fi, interpolation='nearest')\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on which features (pixels) that AdaBoost and Random Forests are using\n",
    "- As for the Boosting methods, it used the overall features of the image. In specific, as for the face, it used corners, edges, and details of the face. In contrast, the random forest used features from the top to bottom like a tree. In specific, it can learn the features of eyes, nose, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For kernel SVM, we can look at the support vectors to see what the classifier finds difficult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svmclf is the trained SVM classifier\n",
    "print(\"num support vectors:\", len(svmrbfcv.best_estimator_.support_vectors_))\n",
    "si  = svmrbfcv.best_estimator_.support_  # get indicies of support vectors\n",
    "\n",
    "# get all the patches for each support vector\n",
    "simg = [imgdata['train'][i] for i in si]\n",
    "\n",
    "# make montage\n",
    "outimg = image_montage(simg, maxw=20)\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.imshow(outimg, cmap='gray', interpolation='nearest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svmclf is the trained SVM classifier\n",
    "print(\"num support vectors:\", len(svmpolcv.best_estimator_.support_vectors_))\n",
    "si  = svmpolcv.best_estimator_.support_  # get indicies of support vectors\n",
    "\n",
    "# get all the patches for each support vector\n",
    "simg = [imgdata['train'][i] for i in si]\n",
    "\n",
    "# make montage\n",
    "outimg = image_montage(simg, maxw=20)\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.imshow(outimg, cmap='gray', interpolation='nearest')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on anything you notice about what the SVM finds difficult (i.e., on the decision boundary or within the margin)\n",
    "- The SVM can capture the overall features from the image. However, those details may be missed, like the details of a specific part of the face."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom kernel SVM\n",
    "\n",
    "Now we will try to use a custom kernel with the SVM.  We will consider the following RBF-like kernel based on L1 distance (i.e., cityblock or Manhattan distance),\n",
    "\n",
    "$$ k(\\mathbf{x},\\mathbf{y}) = \\exp \\left(-\\alpha \\sum_{i=1}^d |x_i-y_i|\\right)$$\n",
    "\n",
    "where $x_i,y_i$ are the elements of the vectors $\\mathbf{x},\\mathbf{y}$, and $\\alpha$ is the hyperparameter.  The difference with the RBF kernel is that the new kernel uses the absolute difference rather than the squared difference. Thus, the new kernel does not \"drop off\" as fast as the RBF kernel using squared distance.\n",
    "\n",
    "- Implement the new kernel as a custom kernel function. The `scipy.spatial.distance.cdist` function will be helpful.\n",
    "- Train the SVM with the new kernel.  To select the hyperparameter $\\alpha$, you need to run cross-validation \"manually\" by: 1) trying different values of $\\alpha$, and running cross-validation to select $C$; 2) selecting the  $\\alpha$ with the highest cross-validation score `best_score_` in `GridSearchCV`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "def kernel(X1, X2, alpha=1.0):\n",
    "    \"Kernel function\"\n",
    "    \n",
    "    dis = spatial.distance.cdist(X1, X2, metric='cityblock')\n",
    "    dis = exp(-alpha * dis)\n",
    "    \n",
    "    return dis\n",
    "\n",
    "\n",
    "paramgrid = {'C': logspace(-4, 4, 3)}\n",
    "svmmodel = model_selection.GridSearchCV(svm.SVC(kernel=kernel), \n",
    "                                      paramgrid, \n",
    "                                      cv=5, \n",
    "                                      n_jobs=-1, \n",
    "                                      verbose=True)\n",
    "\n",
    "svmmodel.fit(trainXn, trainY);\n",
    "print(\"best params:\", svmmodel.best_params_)\n",
    "print(\"best score:\", svmmodel.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.01, 0.05, 0.1, 0.2, 0.5, 1., 10.]\n",
    "\n",
    "\n",
    "for i in alphas:\n",
    "    paramgrid = {'C': logspace(-4, 4, 3)}\n",
    "    svmmodel = model_selection.GridSearchCV(svm.SVC(kernel=kernel), \n",
    "                                          paramgrid, \n",
    "                                          cv=5, \n",
    "                                          n_jobs=-1, \n",
    "                                          verbose=True)\n",
    "\n",
    "    svmmodel.fit(trainXn, trainY);\n",
    "    print(\"best params:\", svmmodel.best_params_)\n",
    "    print(\"best score:\", svmmodel.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict from the model \n",
    "test_pre = svmmodel.predict(testXn)\n",
    "test_acc = metrics.accuracy_score(testY, test_pre) \n",
    "print(\"(SVM Model with more search parameters)\\n testing accuracy =\", test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does using the new kernel improve the results?\n",
    "- Not really."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Image Feature Extraction\n",
    "The detection performance is not that good. The problem is that we are using the raw pixel values as features, so it is difficult for the classifier to interpret larger structures of the face that might be important.  To fix the problem, we will extract features from the image using a set of filters.\n",
    "\n",
    "Run the below code to look at the filter output.  The filters are a sets of black and white boxes that respond to similar structures in the image.  After applying the filters to the image, the filter response map is aggregated over a 4x4 window.  Hence each filter produces a 5x5 feature response.  Since there are 4 filters, then the feature vector is 100 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(imgs, doplot=False):\n",
    "    # the filter layout\n",
    "    lay = [array([-1,1]), array([-1,1,-1]),  \n",
    "               array([[1],[-1]]), array([[-1],[1],[-1]])]\n",
    "    sc=8            # size of each filter patch\n",
    "    poolmode = 'i'  # pooling mode (interpolate)\n",
    "    cmode = 'same'  # convolution mode\n",
    "    brick = ones((sc,sc))  # filter patch\n",
    "    ks = []\n",
    "    for l in lay:\n",
    "        tmp = [brick*i for i in l]\n",
    "        if (l.ndim==1):\n",
    "            k = hstack(tmp)\n",
    "        else:\n",
    "            k = vstack(tmp)\n",
    "        ks.append(k)\n",
    "\n",
    "    # get the filter response size\n",
    "    if (poolmode=='max') or (poolmode=='absmax'):\n",
    "        tmpimg = maxpool(maxpool(imgs[0]))\n",
    "    else:\n",
    "        tmpimg = ndimage.interpolation.zoom(imgs[0], 0.25)        \n",
    "    fs = prod(tmpimg.shape)\n",
    "    \n",
    "    # get the total feature length\n",
    "    fst = fs*len(ks)\n",
    "\n",
    "    # filter the images\n",
    "    X  = empty((len(imgs), fst))\n",
    "    for i,img in enumerate(imgs):\n",
    "        x = empty(fst)\n",
    "\n",
    "        # for each filter\n",
    "        for j,th in enumerate(ks):\n",
    "            # filter the image\n",
    "            imgk = signal.convolve(img, ks[j], mode=cmode)\n",
    "            \n",
    "            # do pooling\n",
    "            if poolmode == 'maxabs':\n",
    "                mimg = maxpool(maxpool(abs(imgk)))\n",
    "            elif poolmode == 'max':\n",
    "                mimg = maxpool(maxpool(imgk))\n",
    "            else:\n",
    "                mimg = ndimage.interpolation.zoom(imgk, 0.25)\n",
    "    \n",
    "            # put responses into feature vector\n",
    "            x[(j*fs):(j+1)*fs] = ravel(mimg)\n",
    "               \n",
    "            if (doplot):             \n",
    "                plt.subplot(3,len(ks),j+1)\n",
    "                plt.imshow(ks[j], cmap='gray', interpolation='nearest')\n",
    "                plt.title(\"filter \" + str(j))\n",
    "                plt.subplot(3,len(ks),len(ks)+j+1)\n",
    "                plt.imshow(imgk, cmap='gray', interpolation='nearest')\n",
    "                plt.title(\"filtered image\")\n",
    "                plt.subplot(3,len(ks),2*len(ks)+j+1)\n",
    "                plt.imshow(mimg, cmap='gray', interpolation='nearest')\n",
    "                plt.title(\"image features\")\n",
    "        X[i,:] = x\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new features\n",
    "img = imgdata['train'][0]\n",
    "plt.imshow(img, cmap='gray', interpolation='nearest')\n",
    "plt.title(\"image\")\n",
    "plt.figure(figsize=(9,9))\n",
    "extract_features([img], doplot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets extract image features on the training and test sets.  It may take a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainXf = extract_features(imgdata['train'])\n",
    "print(trainXf.shape)\n",
    "\n",
    "testXf = extract_features(imgdata['test'])\n",
    "print(testXf.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection using Image Features\n",
    "Now train AdaBoost and SVM classifiers on the image feature data.  Evaluate on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first scale the features\n",
    "scalerf = preprocessing.MinMaxScaler(feature_range=(-1,1))    # make scaling object\n",
    "trainXfn = scalerf.fit_transform(trainXf)   # use training data to fit scaling parameters\n",
    "testXfn  = scalerf.transform(testXf)        # apply scaling to test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost Model\n",
    "# setup the list of parameters to try\n",
    "paramgrid = {'learning_rate': logspace(-6, 0, 3)} \n",
    "# print(paramgrid)\n",
    "\n",
    "# setup the cross-validation object \n",
    "adaclf = ensemble.AdaBoostClassifier(random_state=4487)\n",
    "adacv = model_selection.GridSearchCV(adaclf, paramgrid, cv=5, n_jobs=8) \n",
    "\n",
    "adacv.fit(trainXfn, trainY)\n",
    "\n",
    "# predict from the model \n",
    "train_pre = adacv.predict(trainXfn)\n",
    "train_acc = metrics.accuracy_score(trainY, train_pre) \n",
    "print(\"(AdaBoost Model)\\n training accuracy =\", train_acc)\n",
    "\n",
    "# predict from the model \n",
    "test_pre = adacv.predict(testXfn)\n",
    "test_acc = metrics.accuracy_score(testY, test_pre) \n",
    "print(\"(AdaBoost Model)\\n testing accuracy =\", test_acc)\n",
    "\n",
    "# predY is the prediction from the classifier\n",
    "predY = test_pre\n",
    "Pind = where(predY == 1) # indicies for face predictions\n",
    "Nind = where(predY == 0) # indicies for non-face predictions\n",
    "TP = count_nonzero(testY[Pind] == predY[Pind])\n",
    "FP = count_nonzero(testY[Pind] != predY[Pind])\n",
    "TN = count_nonzero(testY[Nind] == predY[Nind])\n",
    "FN = count_nonzero(testY[Nind] != predY[Nind])\n",
    "\n",
    "TPR = TP / (TP + FN)\n",
    "FPR = FP / (FP + TN)\n",
    "\n",
    "print(\"TP =\", TP)\n",
    "print(\"FP =\", FP)\n",
    "print(\"TN =\", TN)\n",
    "print(\"FN =\", FN)\n",
    "print(\"TPR=\", TPR)\n",
    "print(\"FPR =\", FPR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Model with RBF kernel\n",
    "# setup the list of parameters to try \n",
    "paramgrid = {'C': logspace(-2, 3, 3), \n",
    "             'gamma': logspace(-4, 3, 3)}\n",
    "print(paramgrid)\n",
    "\n",
    "# setup the cross-validation object \n",
    "# pass the SVM object w/ rbf kernel, parameter grid, and number of CV folds \n",
    "svmrbf = svm.SVC(kernel='rbf')\n",
    "svmrbfcv = model_selection.GridSearchCV(svmrbf, \n",
    "                                     paramgrid, \n",
    "                                     cv=5, \n",
    "                                     n_jobs=8, \n",
    "                                     verbose=True)\n",
    "\n",
    "# run cross-validation (train for each split) \n",
    "svmrbfcv.fit(trainXfn, trainY);\n",
    "print(\"best params:\", svmcv.best_params_)\n",
    "\n",
    "# predict from the model \n",
    "train_pre = svmrbfcv.predict(trainXfn)\n",
    "train_acc = metrics.accuracy_score(trainY, train_pre) \n",
    "print(\"(SVM Model with RBF kernel with more search parameters)\\n training accuracy =\", train_acc)\n",
    "\n",
    "# predict from the model \n",
    "test_pre = svmrbfcv.predict(testXfn)\n",
    "test_acc = metrics.accuracy_score(testY, test_pre) \n",
    "print(\"(SVM Model with RBF kernel with more search parameters)\\n testing accuracy =\", test_acc)\n",
    "\n",
    "# predY is the prediction from the classifier\n",
    "predY = test_pre\n",
    "Pind = where(predY == 1) # indicies for face predictions\n",
    "Nind = where(predY == 0) # indicies for non-face predictions\n",
    "TP = count_nonzero(testY[Pind] == predY[Pind])\n",
    "FP = count_nonzero(testY[Pind] != predY[Pind])\n",
    "TN = count_nonzero(testY[Nind] == predY[Nind])\n",
    "FN = count_nonzero(testY[Nind] != predY[Nind])\n",
    "\n",
    "TPR = TP / (TP + FN)\n",
    "FPR = FP / (FP + TN)\n",
    "\n",
    "print(\"TP =\", TP)\n",
    "print(\"FP =\", FP)\n",
    "print(\"TN =\", TN)\n",
    "print(\"FN =\", FN)\n",
    "print(\"TPR=\", TPR)\n",
    "print(\"FPR =\", FPR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis\n",
    "Repeat the error analysis for the new classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Confusion Matrix info has added into the above codes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How has the classifier using image features improved?\n",
    "- Yes! It seems that such features are quite helpful!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test image\n",
    "Now lets try your face detector on a real image.  Download the \"nasa-small.png\" image and put it in the same directory as your ipynb file.  The below code will load the image, crop out image patches and then extract features. (this may take a few minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"nasa-small.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "testimg3 = skimage.io.imread(fname)\n",
    "\n",
    "# convert to grayscale\n",
    "testimg = skimage.color.rgb2gray(testimg3)\n",
    "print(testimg.shape)\n",
    "plt.imshow(testimg, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step size for the sliding window\n",
    "step = 4\n",
    "\n",
    "# extract window patches with step size of 4\n",
    "patches = skimage.util.view_as_windows(testimg, (19,19), step=step)\n",
    "psize = patches.shape\n",
    "# collapse the first 2 dimensions\n",
    "patches2 = patches.reshape((psize[0]*psize[1], psize[2], psize[3]))\n",
    "print(patches2.shape )\n",
    "\n",
    "# histogram equalize patches (improves contrast)\n",
    "patches3 = empty(patches2.shape)\n",
    "for i in range(patches2.shape[0]):\n",
    "    patches3[i,:,:] = skimage.exposure.equalize_hist(patches2[i,:,:])\n",
    "\n",
    "# extract features\n",
    "newXf = extract_features(patches3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now predict using your classifier.  The extracted features are in `newXf`, and scaled features are `newXfn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newXfn  = scalerf.transform(newXf)        # apply scaling to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict from the Adaboost model \n",
    "prednewY = adacv.predict(newXfn)\n",
    "print(\"(Adaboost with more search parameters)\\n Prediction: \", prednewY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape prediction to an image\n",
    "imgY = prednewY.reshape(psize[0], psize[1])\n",
    "\n",
    "# zoom back to image size\n",
    "imgY2 = ndimage.interpolation.zoom(imgY, step, output=None, order=0)\n",
    "# pad the top and left with half the window size\n",
    "imgY2 = vstack((zeros((9, imgY2.shape[1])), imgY2))\n",
    "imgY2 = hstack((zeros((imgY2.shape[0],9)), imgY2))\n",
    "# pad right and bottom to same size as image\n",
    "if (imgY2.shape[0] != testimg.shape[0]):\n",
    "    imgY2 = vstack((imgY2, zeros((testimg.shape[0]-imgY2.shape[0], imgY2.shape[1]))))\n",
    "if (imgY2.shape[1] != testimg.shape[1]):\n",
    "    imgY2 = hstack((imgY2, zeros((imgY2.shape[0],testimg.shape[1]-imgY2.shape[1]))))\n",
    "    \n",
    "# show detections with image\n",
    "#detimg = dstack(((0.5*imgY2+0.5)*testimg, 0.5*testimg, 0.5*testimg))\n",
    "nimgY2 = 1-imgY2\n",
    "tmp = nimgY2*testimg\n",
    "detimg = dstack((imgY2+tmp, tmp, tmp))\n",
    "\n",
    "# show it!\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(imgY2, interpolation='nearest')\n",
    "plt.title('detection map')\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(detimg)\n",
    "plt.title('image')\n",
    "plt.axis('image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict from the SVM Model with RBF kernel model \n",
    "prednewY = svmrbfcv.predict(newXfn)\n",
    "print(\"(SVM Model with RBF kernel with more search parameters)\\n Prediction: \", prednewY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we we will view the results on the image.  Use the below code. `prednewY` is the vector of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape prediction to an image\n",
    "imgY = prednewY.reshape(psize[0], psize[1])\n",
    "\n",
    "# zoom back to image size\n",
    "imgY2 = ndimage.interpolation.zoom(imgY, step, output=None, order=0)\n",
    "# pad the top and left with half the window size\n",
    "imgY2 = vstack((zeros((9, imgY2.shape[1])), imgY2))\n",
    "imgY2 = hstack((zeros((imgY2.shape[0],9)), imgY2))\n",
    "# pad right and bottom to same size as image\n",
    "if (imgY2.shape[0] != testimg.shape[0]):\n",
    "    imgY2 = vstack((imgY2, zeros((testimg.shape[0]-imgY2.shape[0], imgY2.shape[1]))))\n",
    "if (imgY2.shape[1] != testimg.shape[1]):\n",
    "    imgY2 = hstack((imgY2, zeros((imgY2.shape[0],testimg.shape[1]-imgY2.shape[1]))))\n",
    "    \n",
    "# show detections with image\n",
    "#detimg = dstack(((0.5*imgY2+0.5)*testimg, 0.5*testimg, 0.5*testimg))\n",
    "nimgY2 = 1-imgY2\n",
    "tmp = nimgY2*testimg\n",
    "detimg = dstack((imgY2+tmp, tmp, tmp))\n",
    "\n",
    "# show it!\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(imgY2, interpolation='nearest')\n",
    "plt.title('detection map')\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(detimg)\n",
    "plt.title('image')\n",
    "plt.axis('image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_How did your face detector do?_\n",
    "- Classify each block into 'human face' or 'not human face'. And visualize the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try it on your own images.  The faces should all be around 19x19 pixels though.\n",
    "We only used 1/4 of the training data. Try using more data to train it!"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}