{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** \\_\\_\\_\\_\\_\n",
    "\n",
    "**EID:** \\_\\_\\_\\_\\_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS5489 - Tutorial 2\n",
    "## Text Document Classification with Naive Bayes\n",
    "\n",
    "In this tutorial you will classify text documents using Naive Bayes classifers.  We will be working with the dataset called \"20 Newsgroups\", which is a collection of 20,000 newsgroup posts organized into 20 categories.\n",
    "\n",
    "First we need to initialize Python.  Run the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import IPython.core.display         \n",
    "# setup output image format (Chrome works best)\n",
    "IPython.core.display.set_matplotlib_formats(\"svg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from numpy import *\n",
    "from sklearn import *\n",
    "from scipy import stats, special\n",
    "random.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, put the file \"20news-bydate_py3.pkz' into the same directory as this ipynb file. **Do not unzip the file.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will extract 4 classes from the dataset.  Run the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip away headers/footers/quotes from the text\n",
    "removeset = ('headers', 'footers', 'quotes')\n",
    "\n",
    "# only use 4 categories\n",
    "cats      = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "\n",
    "# load the training and testing sets\n",
    "newsgroups_train = datasets.fetch_20newsgroups(subset='train',\n",
    "                           remove=removeset, categories=cats, data_home='./')\n",
    "newsgroups_test  = datasets.fetch_20newsgroups(subset='test', \n",
    "                           remove=removeset, categories=cats, data_home='./')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we check if we got all the data.  The training set should have 2034 documents, and the test set should have 1353 documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"training set size:\", len(newsgroups_train.data))\n",
    "print(\"testing set size: \",  len(newsgroups_test.data))\n",
    "print(newsgroups_train.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number examples in each class.  `newsgroups_train.target` is an array of class values (0 through 3), and `newsgroups_train.target[i]` is the class of the i-th document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"class counts\")\n",
    "for i in [0, 1, 2, 3]:\n",
    "    print(\"{:20s}: {}\".format(newsgroups_train.target_names[i], sum(newsgroups_train.target == i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now have a look at the documents.  `newsgroups_train.data` is a list of strings, and `newsgroups_train.data[i]` is the i-th document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0, 1, 2 ,3]:\n",
    "    print(\"--- document {} (class={}) ---\".format(\n",
    "        i, newsgroups_train.target_names[newsgroups_train.target[i]]))\n",
    "    print(newsgroups_train.data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip:** while you do the tutorial, it is okay to make additional code cells in the file. Â This will allow you to avoid re-running code (like training a classifier, then testing a classifier)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Build document vectors\n",
    "Create the vocabulary from the training data.  Then build the document vectors for the training and testing sets.  You can decide how many words you want in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out the document data and labels\n",
    "traindata = newsgroups_train.data\n",
    "trainY = newsgroups_train.target\n",
    "\n",
    "testdata = newsgroups_test.data\n",
    "testY  = newsgroups_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Bernoulli Naive Bayes \n",
    "Learn a Bernoulli Naive Bayes model from the training set.  What is the prediction accuracy on the test set?  Try different parameters (alpha, max_features, etc) to get the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the most informative words for each category?  Run the below code.\n",
    "\n",
    "Note: `model.coef_[i]` will index the scores for the i-th class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get the word names\n",
    "fnames = asarray(cntvect.get_feature_names())\n",
    "for i,c in enumerate(newsgroups_train.target_names):\n",
    "    tmp = argsort(bmodel.coef_[i])[-10:]\n",
    "    print(\"class\", c)\n",
    "    for t in tmp:\n",
    "        print(\"    {:9s} ({:.5f})\".format(fnames[t], bmodel.coef_[i][t]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Multinomial Naive Bayes model\n",
    "Now learn a multinomial Naive Bayes model using the TF-IDF representation for the documents.  Again try different parameter values to improve the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the most informative features for Multinomial model? Run the below code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the word names\n",
    "fnames = asarray(cntvect.get_feature_names())\n",
    "for i,c in enumerate(newsgroups_train.target_names):\n",
    "    tmp = argsort(mmodel_tf.coef_[i])[-10:]\n",
    "    print(\"class\", c)\n",
    "    for t in tmp:\n",
    "        print(\"    {:9s} ({:.5f})\".format(fnames[t], mmodel_tf.coef_[i][t]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the most informative words differ between the TF-IDF multinomial model and the Bernoulli model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **INSERT YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, look at a few of the misclassified documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you get any intuition or reason why they were misclassified?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **INSERT YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4. Effect of smoothing\n",
    "The smoothing (regularization) parameter has a big effect on the performance.  Using the Multinomial TF-IDF models, make a plot of accuracy versus different values of alpha. For each alpha, you need to train a new model. Which alpha value yields the best result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Effect of vocabulary size\n",
    "The vocabulary size also affects the accuracy.  Make another plot of accuracy versus vocabulary size.  Which vocabulary size yields the best result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Poisson Naive Bayes\n",
    "\n",
    "Now we will implement a Naive Bayes classifier using a Poisson distribution to model the count of each word appearing in the document.  Recall that the Poisson distribution is:\n",
    "$$ \\mathrm{Poisson}(x,\\mu) = \\frac{1}{x!}e^{-\\mu} \\mu^x$$\n",
    "where $x \\in \\{0,1,2,\\cdots\\}$ is a counting number, and $\\mu$ is the Poisson mean (arrival rate).\n",
    "\n",
    "Here is some code showing how to compute the Poisson distribution using scipy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poisson distribution\n",
    "from scipy.stats import poisson\n",
    "\n",
    "# compute log Poisson(x, lambda)\n",
    "px = poisson.logpmf(arange(0,20).reshape((20,1)), mu=[[1., 2., 3.5]])\n",
    "\n",
    "# NOTE: the function respects broadcasting\n",
    "# x is a column vector, and mu is a row vector\n",
    "# in the output px, each column is the log Poisson values for one mu\n",
    "print(px)\n",
    "\n",
    "# make a plot\n",
    "plt.title('example Poissons')\n",
    "plt.plot(arange(0,20), exp(px), '.-');\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('p(x)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how to use the Poisson to create a Naive Bayes model. Let $x_i$ be the number of times the i-th word appears in the document. Then we model $x_i$ as a Poisson distribution for each class $c$,\n",
    "  $$p(x_i|y=c) = \\mathrm{Poisson}(x_i, \\mu_{i,c})$$\n",
    "where $\\mu_{i, c}$ is the Poisson parameter for the i-th word in the c-th class.  Given the data $\\{x_i^{(1)}, \\cdots x_i^{(N)}\\}$, corresponding the counts of the i-th word in the documents in the c-th class, $\\mu_{i,c}$ is estimated as the mean of the data: $\\mu_{i,c} = \\frac{1}{N} \\sum_{n=1}^N x_i^{(n)}$.\n",
    "\n",
    "Finally, given the document $\\mathbf{x} = [x_1,\\cdots,x_D]$, the document class-conditional likelihood is:\n",
    "  $$ p(\\mathbf{x}|y=c) = \\prod_{i=1}^D p(x_i|y=c) = \\prod_{i=1}^D \\mathrm{Poisson}(x_i, \\mu_{i,c})$$\n",
    "or CCD log-likelihood is\n",
    "  $$ \\log p(\\mathbf{x}|y=c) = \\sum_{i=1}^D \\log \\mathrm{Poisson}(x_i, \\mu_{i,c})$$\n",
    "\n",
    "Write a class for the Poisson Naive Bayes model.  Starting with the `GaussBayes` class from lecture as the template, you only need to change the estimation of the parameters $\\mu_{i,c}$ and the computation of the log CCD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test your Poisson NB model on the Newsgroup dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the Poisson NB model compare with the other models that you tested?  Is this a good model for documents?\n",
    "\n",
    "- **INSERT YOUR ANSWER HERE**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
